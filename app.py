import streamlit as st
import pandas as pd
import re
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from bertopic import BERTopic
from sentence_transformers import SentenceTransformer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

# T√©l√©chargement des ressources nltk
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Configuration de la page
st.set_page_config(
    page_title="BERTopic pour les Assurances",
    page_icon="üìä",
    layout="wide",
)

# Fonction pour regrouper les classes des notes
def regrouper_notes(note):
    if note in [1, 2]:
        return 0  # N√©gatif
    elif note == 3:
        return 1  # Neutre
    else:  # 4 ou 5
        return 2  # Positif
    
# Fonction de pr√©traitement du texte
def preprocess_text(text):
    text = re.sub(r"[^\w\s]", "", text)  # Suppression des signes de ponctuation
    text = text.lower()  # Passage en minuscules
    lemmatizer = WordNetLemmatizer()
    tokens = word_tokenize(text)  # Tokenisation
    stop_words = set(stopwords.words('english'))  # Liste des mots vides
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]  # Lemmatization et suppression des stopwords
    return " ".join(tokens)  # Retourner le texte nettoy√©

# Fonction pour combiner les fichiers Excel t√©l√©charg√©s
def combine_excel_files(uploaded_files):
    dataframes = []
    for uploaded_file in uploaded_files:
        try:
            df = pd.read_excel(uploaded_file)
            dataframes.append(df)
            st.success(f"‚úÖ Fichier '{uploaded_file.name}' charg√© avec succ√®s!")
        except Exception as e:
            st.error(f"‚ùå Erreur lors du chargement du fichier '{uploaded_file.name}': {e}.")
    combined_data = pd.concat(dataframes, ignore_index=True)
    return combined_data

# Charger un mod√®le BERTopic existant ou en cr√©er un nouveau
@st.cache_resource
def train_or_load_bertopic_model(texts):
    embedding_model = SentenceTransformer("all-MiniLM-L6-v2")  # Charger l'embedding model
    topic_model = BERTopic(embedding_model=embedding_model)  # Initialiser le mod√®le
    topics, probs = topic_model.fit_transform(texts)  # Entra√Æner le mod√®le
    return topic_model, topics, probs

# Titre principal
st.title("üìä Topic Modeling avec BERTopic pour les Assurances")

# Ajout d'une description de l'application
st.markdown(
    """
    Cette application utilise **BERTopic** pour extraire des th√®mes et analyser les avis des assureurs. 
    T√©l√©chargez vos fichiers Excel contenant les avis et explorez les th√®mes identifi√©s.
    """
)

# √âtape 1 : T√©l√©chargement des fichiers Excel
st.sidebar.header("√âtapes :")
st.sidebar.markdown("1Ô∏è‚É£ T√©l√©chargez vos fichiers Excel.\n2Ô∏è‚É£ S√©lectionnez un assureur.\n3Ô∏è‚É£ Entra√Ænez le mod√®le et visualisez les r√©sultats.")

uploaded_files = st.file_uploader(
    "üìÇ T√©l√©chargez les fichiers Excel contenant des avis d'assureur.",
    type=["xlsx", "xls"],
    accept_multiple_files=True,
)

st.divider()  # S√©parateur visuel

if uploaded_files:
    # Combiner les fichiers t√©l√©charg√©s
    st.header("üîÑ Donn√©es combin√©es")
    data = combine_excel_files(uploaded_files)
    st.write("Aper√ßu des donn√©es combin√©es :", data.head())

    # V√©rification de la pr√©sence des colonnes n√©cessaires
    if "avis" in data.columns and "assureur" in data.columns:
        # Pr√©traitement des avis
        data['processed_reviews'] = data['avis_en'].fillna("").apply(preprocess_text)

        # S√©lection de l'assureur
        assureur_choices = data['assureur'].unique()
        selected_assureur = st.selectbox("üë§ Choisissez un assureur :", assureur_choices)
        filtered_data = data[data['assureur'] == selected_assureur]

        st.subheader(f"üìã Avis de l'assureur s√©lectionn√© : {selected_assureur}")
        st.write(filtered_data[['avis_en', 'processed_reviews']].head())

        # Entra√Æner le mod√®le BERTopic pour l'assureur s√©lectionn√©
        if st.button("üöÄ Entra√Æner le mod√®le pour cet assureur"):
            with st.spinner("‚è≥ Entra√Ænement du mod√®le en cours..."):
                texts = filtered_data['processed_reviews'].tolist()
                topic_model, topics, probs = train_or_load_bertopic_model(texts)

            st.success("‚úîÔ∏è Mod√®le entra√Æn√© avec succ√®s!")

            # Ajouter les topics d√©tect√©s au DataFrame filtr√©
            filtered_data['topic_number'] = topics
            filtered_data['topic_name'] = filtered_data['topic_number'].apply(
                lambda x: topic_model.get_topic(x)[0][0] if x != -1 else "Pas de th√®me"
            )

            # Afficher les th√®mes d√©tect√©s avec leurs mots-cl√©s
            st.subheader("üîç Th√®mes d√©tect√©s et leurs mots-cl√©s :")
            st.write(topic_model.get_topic_info())

            # Ajouter les mots-cl√©s pour chaque avis
            filtered_data['keywords'] = filtered_data['topic_number'].apply(
                lambda x: ", ".join([kw[0] for kw in topic_model.get_topic(x)]) if x != -1 else "Pas de mots-cl√©s"
            )

            # Afficher le DataFrame mis √† jour
            st.subheader("üìä Donn√©es avec les th√®mes d√©tect√©s :")
            st.write(filtered_data[['avis_en', 'processed_reviews', 'topic_name', 'keywords']].head())
            
            # S√©lectionner un th√®me sp√©cifique
            st.subheader("üîç S√©lectionnez un th√®me pour voir les avis associ√©s")
            topic_choices = filtered_data['topic_name'].unique()
            selected_topic = st.selectbox("Choisissez un th√®me :", topic_choices)

            # Filtrer les donn√©es selon le th√®me s√©lectionn√©
            filtered_topic_data = filtered_data[filtered_data['topic_name'] == selected_topic]

            st.write(f"Avis associ√©s au th√®me '{selected_topic}':")
            st.write(filtered_topic_data[['avis_en', 'processed_reviews', 'keywords']])
            
            # T√©l√©charger le r√©sultat en fichier Excel
            csv_data = filtered_data.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="‚¨áÔ∏è T√©l√©charger les r√©sultats",
                data=csv_data,
                file_name=f"topics_{selected_assureur}.csv",
                mime="text/csv",
            )



            #Analyse des sentiments 
        if st.button("üß† Analyser les sentiments"):
            if "note" in filtered_data.columns and "processed_reviews" in filtered_data.columns:
                # Regrouper les notes en classes de sentiments
                filtered_data['classe_sentiment'] = filtered_data['note'].apply(regrouper_notes)

                # Pr√©parer les donn√©es pour l'entra√Ænement
                X = filtered_data['processed_reviews']
                y = filtered_data['classe_sentiment']
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                # Vectorisation des avis
                tfidf = TfidfVectorizer(stop_words='english', max_features=5000)
                X_train_tfidf = tfidf.fit_transform(X_train)
                X_test_tfidf = tfidf.transform(X_test)

                # Entra√Æner le mod√®le de classification
                model = RandomForestClassifier(random_state=42)  
                model.fit(X_train_tfidf, y_train)

                # Pr√©dire les sentiments
                y_pred = model.predict(X_test_tfidf)

                # Afficher le rapport de classification
                st.subheader("üìä Rapport de classification")
                report = classification_report(y_test, y_pred, target_names=["N√©gatif", "Neutre", "Positif"], output_dict=True)
                st.write(pd.DataFrame(report).transpose())
                st.write(f"Pr√©cision globale : {accuracy_score(y_test, y_pred):.2f}")

                # Ajouter les pr√©dictions au DataFrame
                filtered_data['sentiment_pred'] = model.predict(tfidf.transform(filtered_data['processed_reviews']))

                # Mapper les valeurs num√©riques aux labels
                sentiment_map = {0: "N√©gatif", 1: "Neutre", 2: "Positif"}
                filtered_data['sentiment_label'] = filtered_data['sentiment_pred'].map(sentiment_map)

                # Afficher les r√©sultats enrichis
                st.subheader("üìã Donn√©es enrichies avec les sentiments pr√©dits")
                st.write(filtered_data[['avis_en', 'processed_reviews', 'note', 'sentiment_label']])

                # T√©l√©charger les r√©sultats
                csv_data_sentiment = filtered_data.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="‚¨áÔ∏è T√©l√©charger les r√©sultats avec sentiments",
                    data=csv_data_sentiment,
                    file_name=f"sentiment_analysis_{selected_assureur}.csv",
                    mime="text/csv",
                )
    else:
        st.error("üö® Le fichier Excel doit contenir les colonnes 'avis' et 'assureur'.")
else:
    st.info("üì• Veuillez t√©l√©charger des fichiers pour commencer.")



